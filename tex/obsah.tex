%=========================================================================

\chapter{Úvod}
World Wide Web (dále jen WWW) dokumenty jsou stále více využívanějšími sdělovacími prostředky. Jejich počet neustále roste [zdroj]. Využití WWW dokumentů se nachází. WWW dokumenty se vuyžívají na širokou škálu účelů. Můlžeme narazit na dokumenty se spíše statickým obsahem jako jsou blogy, firemní reprezentace atd. Můžeme ale také narazit na velice dynamické dokumenty jako jsou internetové vyhledavače. informační systémy, webové aplikace aj. 

Množství webových stránek na doméně je téměř neomezený a na internetu lze najít domény o několika stránek, ale i domény jejichž obsah roste po více jak deset let. Takové domény pak cyklicky procházejí refactoringem kodu a někdy i celého systému. Může se pak stát, že se řada stránek zapomene či vytratí. Či naopak, že systém roste a nalepují se na něj další a další časti mnohdy zbytečně. Stejně tak se staré neodstraní, třeba i z důvodu, že v programátorském týmu "nikdo nemá tušení co to dělá a co se stane, pokud se to dá pryč". 

Z tohoto a dalších důvodů využívaji týmy mnoho nástrojů, které analyzují zpracování požadavku serveru. Jedná se o měření rychlosti zpracování backendu a frontendu. Velikost stahovaných klientských zdrojů jako jsou například soubory kaskádových stylů, obrázky či Javascriptové knihovny. Jednim z těchto nástrojů jsou Webové crawlery, neboli pavouci. 

Pavouci našli největší využití hlavně u internetových vyhledavačů. Jsou navrženi tak taby v krátkém čase dokázali zpracovávat najednou velké množství stránek z různých domén. Při zpracovávání hledá odkazy na další stránky a ty také analyzuje. Vzhledem k velikosti a neústalého růsta pavouci mnohdy svou práci nikdy nekončí, nebo jsou spouštěni pravidelně. Úloha pavouků může být různá. 

Mým cílem je vytvořit pavouka, který bude analyzovat pouze jednu doménu. Předpokládá se, tedy že bude zpracovávat pouhé stovky až tisíce stránek. Výstupem analýzy mají být programátorům užitečná data jako grafické zobrazení provázanosti stránek. Měření rychlosti a analýza stahování stránek. Rendering stránek. Součástí analýzy je možno také sledování chyb Javascriptu či validace DOM objektu.

V této práci se budu věnovat několika hlavních částí této problematiky. První část bude věnována analýze problematiky pavouků. V druhé části zpracuji návrh vlastního pavouka. Ve třetí části budu řešit implementaci vyhotoveného návrhu a poslední část je věnována experimentům s pavoukem a výsledky jeho analýz.

\subsection{Zadání}
\begin{enumerate}
	\item Prostudujte existující přístupy k automatizovanému procházení webových stránek.
	\item Seznamte se s existujícími knihovnami a nástroji pro získávání, reprezentaci a zpracování HTML dokumentů. Zaměřte se na platformu Java.
	\item Navrhněte architekturu rozšiřitelného nástroje pro automatické procházení vymezené množiny webových stránek provázaných odkazy s cílem jejich další analýzy.
	\item Po dohodě s vedoucím implementujte navržený nástroj na vhodné platformě.
	\item Implementujte funkce pro analýzu rychlosti stahování stránek a odkazovaných dat a pro vyhledání formulářů ve stránkách.
	\item Vytvořte webové rozhraní umožňující průběžně sledovat procházení stránek a získané výsledky.
	\item Proveďte testování vytvořeného nástroje na reálných dokumentech.
	\item Zhodnoťte dosažené výsledky a navrhněte možná další rozšíření.
\end{eumerate}

\newpage
\chapter{Teorie}
něco o WWW bla bla bla, tohle nemám ráda

\subsection{Vyhledávání URL}
Vyhledání dalších hypertextových odkazů je možné pouze u těch stránek, které obsahují DOM objektu. Prohledáním vybraných elementů, můžeme získat potřebné odkazy. Mezi zmiňované elementy patří\footnote{Je potřeba brát v potaz, že URL  mohou být v dokumentu vloženy jako pouhý text či při zpracování události javascriptem. Tyto odkazy pavouk pochopitelně nenajde.}.

\begin{itemize}
	\item \texttt{<a></a>} atribut \texttt{href}
	\item \texttt{<form></form>} atribut \texttt{action}
	\item \texttt{<link>} atribut \texttt{href}
	\item \texttt{<script></script>} atribut \texttt{src}
	\item \texttt{<style></style>} atribut \texttt{src}
\end{itemize}

\subsection{Analýza URL}
Uniform Resource Locator (dále jen URL, neboli též adresa) jsou definovány v (RFC 3986). Je potřeba rozlišit relativní a absolutní adresu. V případě relativní adresy se zohledňuje aktualní adresa dokumentu. Součástí URL může být též kotva, kotva je definována atributem \texttt{id} v elementu \texttt{<a>}, kotvy nemají pro pavouka žádný význam a jsou tedy ignorovány. V případě nalezení většího množství odkazů se stejnou adresou v dokumentu, pavouk se zachová jako by pracoval s adresou jedinou.

\subsection{Zaznamenání časových událostí}
Rychlost stažení a zobrazení webového dokumentu je pro uživatele značně důležité.... bla bla


\subsection{Vykreslení dokumentu}


\newpage
\chapter{Návrh aplikace}
Aplikace je složena z několika částí. Jedná se o algoritmus pavouka, který stahuje a analyzuje dokumenty. Databázovým uložištěm, které uchovává analyzované data a grafická nadstavba (GUI) přes kterou je aplikace řízena. Pro vykreslování dokumentů jsou využity technologie Headless Browseru, v tomto případě byl využit PhantomJS, který pracuje na vykreslovacím jádře WebKit.

\chapter{Java}
Byla využita platforma Java s platformou JavaFX, která umožňuje tvorbu Rich Internet Applications (dále jen RIA). JavaFX aplikace je možno využít i jako desktopové aplikace. Aplikace vytvořena součástí této práce byla naprogramována pro Java 8, JavaFX 8.

\chapter{Analýza DOM objektu}


\chapter{Databáze}

\newpage
\chapter{Implementace aplikace}

\newpage
\chapter{Experimenty}

\newpage
\chapter{Závěr}

\chapter{Slovníček pojmů}
\begin{itemize}
	\item Frontend - Klientská část zpracování požadavku
	\item Backend - Serverová část zpracování požadavku
	\item Crawler - pavouk
	\item Resource - zdroj/webový objekt
\end{itemize}

%=========================================================================
