%=========================================================================

\chapter{Úvod}
World Wide Web (dále jen WWW) dokumenty jsou èím dál více vyu¾ívanými sdìlovacími prostøedky. Jejich poèet neustále roste\cite{webstats}. WWW dokumenty se vyu¾ívají pro ¹irokou ¹kálu úèelù. Mù¾eme narazit na dokumenty se spí¹e statickým obsahem jako jsou blogy, firemní reprezentace a jiné, ale také na dokumenty s~kompletnì dynamicky generovaným obsahem jako jsou napø. internetové vyhledávaèe. informaèní systémy èi dal¹í webové aplikace.

Mno¾ství webových stránek na doménì je témìø neomezené. Na Internetu lze najít domény o~nìkolika stránkách, ale i domény, jejich¾ obsah roste po více jak deset let a obsahují stovky a¾ tisíce. Takové domény pak cyklicky procházejí refactoringem kódu èi celého systému. Mù¾e se pak stát, ¾e se øada stránek zapomene èi vytratí. Èi naopak, ¾e systém roste a nalepují se na nìj dal¹í a dal¹í èásti, mnohdy zbyteènì. Stejnì tak se staré neodstraní, tøeba i z~dùvodu, ¾e v~programátorském týmu "nikdo nemá tu¹ení, co to dìlá, a co se stane, pokud se to dá pryè". 

Z~tohoto a dal¹ích dùvodù vyu¾ívají týmy mnoho nástrojù, které analyzují zpracování dotazù na server. Jedná se o~mìøení rychlosti zpracování backendu a frontendu, velikost stahovaných klientských zdrojù jako jsou napøíklad soubory kaskádových stylù, obrázky èi Javascriptové knihovny. Jednim z~tìchto nástrojù jsou Webové crawlery, neboli pavouci.

Pavouci na¹li nejvìt¹í vyu¾ití hlavnì u~internetových vyhledavaèù. Jsou navr¾eni tak, aby v~krátkém èase dokázali zpracovávat najednou velké mno¾ství stránek z~rùzných domén. Pøi zpracovávání hledají odkazy na dal¹í stránky a ty následnì analyzují. Vzhledem k~velikosti a neustalému rùstu internetu pavouci mnohdy svou práci nikdy nekonèí.

Mým cílem je vytvoøit pavouka, který bude analyzovat pouze jednu doménu. Pøedpokládá se tedy, ¾e bude zpracovávat pouhé stovky a¾ tisíce stránek. Výstupem analýzy mají být programátorùm u¾iteèná data jako grafické zobrazení provázanosti stránek. Mìøení rychlosti stahování stránek a vykreslování stránek. Souèástí analýzy mù¾e být také sledování chyb Javascriptu èi validace DOM stromu. 

V~této práci se budu vìnovat nìkolika hlavním èástem této problematiky. Kapitola \ref{ch:theory} bude vìnována analýze problematiky pavoukù. V~kapitole \ref{ch:plan} zpracuji návrh vlastního pavouka. Poté kapitola \ref{ch:implementation} øe¹í implementaci vyhotoveného návrhu. Nakonec rozeberu výsledky implementované aplikace.

\newpage
\chapter{Teorie}
\label{ch:theory}
Tato kapitola je vìnována teoritickému zpracováním problematiky analýzy webových stránek. Web lze reprezentovat jako graf, ve kterém uzly jsou dokumenty identifikované URL a hrany hypertextové odkazy. Cílem pavouka je projít podgraf tohoto grafu vymezený poèátaèním uzlem a dal¹ími omezeníni jako specifikace povolených domén. Robot pøi procházení mù¾e provést jednoduchou analýzu dokumentu jako zaznamenání návratového kodu serveru, extrakce hypertextových odkazù, vyhledání formuláøù apod.

\section{Souèasní pavouci}
\label{sec:today_crawlers}
Dnes se pavouci vyu¾ívají pøevá¾nì k~indexování internetu pro internetové vyhledávaèe. Mezi ty nejvíce známe mù¾eme zaøadit Google èi Bing. Implementace tìchto pavoukù je èasto uzavøená a veøejnosti jsou známy pouze omezené informace o~tom, jak tito pavouci pøistupují na jejich stránky.

Vyhledávaè Bing na svých stránkách uveøejòuje seznam pavoukù, které vyu¾ívá k~jakým úèelùm. Kromì pavoukù \texttt{Bingbot}, který plní funkci indexování, se mù¾eme doèíst i o~pavoukù zpracovávajícím audiovizuální data \texttt{MSNBot-Media} èi o~pavouku vykreslujícím obsah webu \texttt{BingPreview}. \cite{bing}

Kromì pavoukù procházejících a indexujících celý internet existuje i celá øada úzce specializovaných pavoukù pro urèitou èinnost.

\texttt{skipfish\footnote{https://code.google.com/p/skipfish/}} je Open Source pavouk testující zabezpeèení domény a odhalující slabá místa, která by mohli vyu¾ít útoèníci. Výsledkem testu je interaktivní mapa stránek.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{skipfish}
  \caption{Skipfish} \label{fig:skipfish}
\end{figure}

\texttt{HTTrack\footnote{https://www.httrack.com/}} je pavouk, který po zadání adresy prochází webový obsah a u~u¾ivatele tvoøí jeho offline kopii. Obsah je strukturován do stejné adresáøové hiearchie jako na serveru a zkonstruuje relativní hypertextové odkazy. Po vytvoøení kopie lze lokálnì ulo¾ené stránky procházet v~prohlí¾eèi. Pavouk umí také aktualizovat ji¾ existující kopie webu a lze ho tak vyu¾it k~vytvoøení a udr¾ování zrcadlových webù, tedy webù, které mají stejný obsah. Zrcadlování webù je oblíbená taktika, jak zabezpeèit udr¾ení obsahu online pøi výpadcích èi útocích na webové servery.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{httrack}
  \caption{HTTrack} \label{fig:httrack}
\end{figure}

Pavouci ve své povaze pøistupují k~webovým serverùm v mnohem vìt¹ím meøítku ne¾ obyèejný u¾ivatel. Toto mù¾e znamenat, ¾e server klasifikuje pavouka jako nebezpeèného robota èi snad pokus o~DDos útok a zaká¾e pavoukùv pøístup k~datùm serveru. Tento pøípad mù¾e nastat i v~na¹í aplikaci. Bohu¾el ka¾dý webový server mù¾e nastavit tento limit na jiné úrovni a ka¾dý se také v~pøípadì pøekroèení limitu mù¾e zachovat jinak. Nìkteré servery se mohou bránit sní¾ením priority odpovìdí, jiné neodpovídáním úplnì. Spoleènost google na svých stránkách uvádí, ¾e GoogleBot nepøistoupí ke stránce èastìji ne¾ jednou za nìkolik sekund. \cite{google} Takové umìlé zpomalení prohledání v~mé aplikaci se mù¾e výraznì podepsat na èas potøebn0m k~vyhotovení analýzy a z~toho dùvodu jsem se rozhodla tuto metodu vylouèit.

\section{Analýza URL}
\label{sec:analysis}
Uniform Resource Locator (dále jen URL, neboli té¾ adresa) je definován v~\texttt{RFC 3986}\cite{rfc3986}. Je potøeba rozli¹it relativní a absolutní adresu. V~pøípadì relativní adresy se zohledòuje aktuální adresa dokumentu. Souèástí URL mù¾e být té¾ kotva, která je definována atributem \texttt{id} v~elementu \texttt{<a>}. Kotvy nemají pro pavouka ¾ádný význam a jsou tedy ignorovány. V~pøípadì nalezení vìt¹ího mno¾ství odkazù se stejnou adresou v~dokumentu, pavouk se zachová, jako by pracoval s~adresou jedinou.

Pavouk by také mìl být pøipraven èelit generovaným hypertexovým odkazùm, jako jsou stránky s~dynamickým obsahem, které se mohou jevit z~pohledu pavouka jako nekoneèné. \cite{mining}

Velkým oøí¹kem mohou být té¾ \texttt{GET} parametry, které jsou souèástí URL. Tyto parametry mají nejednoznaèný význam a pavouk nemù¾e vìdìt, zda jim má vìnovat pozornost. GET parametr mù¾e, ale nemusí význam pro vykreslení dokumentu. 
Mohou existovat i stránky obsahující odkazy s~velkým mno¾stvím opakujících se GET parametrù. GET parametry se v~URL adrese uvádìjí za cestou. První parametr je oznaèen otazníken a následuje \texttt{jméno\_parametru=hodnota\_parametru}, dal¹í parametry jsou oddìleny ampersandem. Na poøadí uvedení parametru nezále¾í, jeliko¾ seznam parametrù je ve své podstatì asociaèní pole. Pavouk by se mìl s~touto vlastností poèítat a nevidìt rozdíl mezi tìmito uvedenými odkazy:

\begin{center}
  \url{http://www.domain.com/index.php?param1=1&param2=2}\\
  \url{htpp://www.domain.com/index.php?param2=2&param1=1}
\end{center}
\section{Extrakce URL}
\label{sec:extraction}
Extrakce adres je provedena analýzou HTML webových dokumentù. Prozkoumáním vybraných elementù je mo¾no získat potøebné odkazy. Mezi zmiòované elementy patøí:\footnote{Je potøeba brát v~potaz, ¾e URL  mohou být v~dokumentu vlo¾eny také jako pouhý text èi pøi zpracování události javascriptem. Tyto odkazy pavouk pochopitelnì nenajde.}

\begin{itemize}
	\item \texttt{<a></a>} atribut \texttt{href}
	\item \texttt{<form></form>} atribut \texttt{action}
	\item \texttt{<link>} atribut \texttt{href}
	\item \texttt{<script></script>} atribut \texttt{src}
	\item \texttt{<style></style>} atribut \texttt{src}
\end{itemize}

V~závislosti na povaze atributu je mo¾no pøedpovídat, na jaký mime typ webového objektu odkaz ukazuje. Jestli¾e extrahujeme atributy src z~tagu \texttt{script} a \texttt{style}, mù¾eme si být jisti, ¾e mime type bude text/css èi text/javascript. Takto mù¾eme konkretizovat zpracování odkazù, jeliko¾ odkazy v~tìchto souborech hledat nebudeme.

\section{Zaznamenání èasových událostí}
\label{sec:time_events}
Pro u¾ivatele je dùle¾itý co nejkrat¹í èas mezi odesláním po¾adavku na server a zobrazením stránky. Tento èas je mo¾né rozdìlit na dvì hlavní èásti a to:
\begin{itemize}
 \item èas strávený zpracováním po¾adavku na serveru - \texttt{Backend}
 \item èas strávený sta¾ením a zobrazením zdrojových dokumentù - \texttt{Frontend}
\end{itemize}
Webová stránka, která se zobrazí u¾ivateli v~prohlí¾eèi, je mnohdy slo¾ena z~více souborù. Jedná se o~HTML/XML dokument, ale také o~obrázky, Kaskádove styly, Javascript a dal¹í soubory. Moderní prohlí¾eèe dnes doká¾í stahovat více souborù z~jednoho serveru najednou, aby èas strávený stahováním co nejvíce urychlily. Mno¾ství vláken se v¹ak u~ka¾dého prohlí¾eèe li¹í a u¾ivatel mù¾e s~touto hodnotou manipulovat. \cite{sharding}

Namìøené èasy musíme také pova¾ovat za nepøíli¹ prùkazné. Server mù¾e odpovídat rychleji èi pomaleji v~závislosti na souèasném zatí¾ení u¾ivatelskými po¾adavky. Prùkazných hodnot by se dalo dosáhnout pomocí pravidelného a dlouhodobého mìøení

\newpage
\chapter{Návrh aplikace}
\label{ch:plan}
Aplikace je slo¾ena z~nìkolika èástí. Jedná se o~algoritmus pavouka, který stahuje a analyzuje dokumenty, databázové ulo¾i¹tì, které uchovává analyzovaná data a grafickou nadstavbu, pøes kterou je aplikace øízena. Pro vykreslování dokumentù jsou vyu¾ity technologie Headless Browseru, v~tomto pøípadì byl vyu¾it PhantomJS, který pracuje na vykreslovacím jádøe WebKit.

\section{Java}
\label{sec:java}
Byla vyu¾ita platforma Java s~platformou JavaFX, která umo¾òuje tvorbu Rich Internet Applications\cite{java}. JavaFX aplikace je mo¾no vyu¾ít i jako desktopové aplikace. Aplikace vytvoøena souèástí této práce byla naprogramována pro Java 8, JavaFX 8.

\section{Specifikace prohledávaného prostoru}
Cílem aplikace je analyzovat pouze jedinou doménu. Pøi prohledávání je nutno zamezit tomu, aby pavouk pavouk zabloudil na cizí domény a prohledával zcela jiné èásti internetu. Toho je dosa¾eno kontrolou domény nejvy¹¹ího soukromého øádu spoleènì s~veøejným suffixem. Pokud se doména tohoto øádu nebo suffix li¹í, adresa se neprohledává.

Je tøeba také poèítat s~tím, ¾e mno¾ství dokumentù a odkazù na doménì není pøedem známo. Doména mù¾e obsahovat nìkolik desítek dokumentù, ale i nìkolik stovek. Aplikace musí být na tuto skuteènost pøipravena a v~pøípadì procházení takto velké domény zareagovat. Co¾ se uskuteèní stanovením maximální hloubky prohledávání. Pøed prohledáním prvního dokumentu je aktualní hloubka 0 a ka¾dým dal¹ím dokumentem se hodnota zvý¹í o~1. V~pøípadì dosa¾ení maximální hloubky prohledávání se z~tohoto dokumentu neextraktují dal¹í adresy.

Mno¾ství webových stránek obsahuje mnohdy èást s~dynamicky generovaným obsahem, jeho¾ analýza by spotøebovala pøíli¹ velké mno¾ství prostøedkù, èi nás tato èást nezajímá. Mù¾e se jednat o~blogy, fora, èi jiné aplikace, kde obsah tvoøí pøevá¾nì u¾ivatelé stránek. V~opaèném pøípadì mohou být webové stránky pøítomny na nìkolika doménách najednou. Z~tohoto dùvodu se prohledávání øídí také podle u¾ivatelem definovaných pravidel. Pravidlo, které zamezí prohledávání èásti domény (subdomény) a omezí tak prohledávaný prostor a pravidlo, které naopak povolí prohledávání na dal¹ích doménách a zvìt¹í tím prohledávaný prostor.

\section{Analýza DOM stromu}
\label{sec:dom_analysis}
Extrakce adres z~HTML dokumentù je mo¾ná za pomocí prohledání Document Object Model (dále jen DOM). DOM prezentuje webový dokument jako strom, který je mo¾no procházet a manipulovat s~ním. Ve~stromu se hledají elementy a atributy zmínìné v~\ref{sec:extraction}. Vyta¾ené adresy se musí dále zpracovat, jak bylo popsáno v~\ref{sec:analysis}, k~adrese se také pøidá záznam na kterém dokumentu byl nalezen a následnì se vlo¾í do fronty ke zpracování.

Pro práci s~DOM stromem a extrakci adres je nejjednodu¹¹í vyu¾ít HTML parser, který pøevede dokument do struktur jazyka pro pøímou manipulaci. Implementací takového parseru je v~Javì hned nìkolik. 
\begin{itemize}
 \item \texttt{NekoHTML\footnote{http://nekohtml.sourceforge.net/}}  Jednoduchý HTML parser, doká¾e se vypoøádat s~øadou men¹ích chyb v~dokumentech.
 \item \texttt{HTMLCleaner\footnote{http://htmlcleaner.sourceforge.net/}} OpenSource HTML parser navr¾ený tak, aby zpracoval nevalidní dokumenty s~vìt¹ím mno¾stvím záva¾ných chyb. Po zpracování HTML dokumentu vytvoøí dobøe strukturovaný XML dokument, k~elementùm je proto mo¾no pøistupovat pomocí XPath
 \item \texttt{jsoup\footnote{http://jsoup.org}} HTML parser navr¾ený na zpracování také nejnovìj¹ího standardu HTML5. Takté¾ zpracuje nevalidní dokumenty s~vìt¹ím mno¾stvím chyb. Výsledkem zpracování je DOM strom, se kterým je mo¾no pracovat pomocí klasických javascriptových funkcí jako \texttt{getElementById, getElementByClass}, èi pomocí CSS a JQuery selectoru. Z~tohoto dùvodu jsem se rozhodla vyu¾ít právì tento parser.
\end{itemize}

\section{Ulo¾ení dat}
\label{sec:data_storage}
Jednou z~hlavních otázek bylo, kam ulo¾it data vytvoøená analýzou. Pøi pøípravì mé aplikace jsem tuto otázku hluboce podcenila, první zku¹ební prototypy ukládaly v¹echna data do RAM pamìti. I~u~velice malých webových stránek se vytvoøilo velké mno¾ství objektù. Takové velké mno¾ství neustále ulo¾ených objektù zpùsobilo naalokování nìkolika GiB pamìti a následný pád aplikace.

Rozhodla jsem se vyu¾ít databázi pro ukládání vìt¹inu dat.

\subsection{Databáze}
\label{subsec:data_database}
Jako databáze byla zvolena \texttt{OrientDB 2.0.X Community Eddition\footnote{V prùbìhu vývoje aplikace byla verze nìkolikrát aktualizovaná}}, jedná se o~hybridní NoSQL databáze umo¾òujíci pracovat jak v~Dokument (\texttt{MongoDB\footnote{https://www.mongodb.org/}}), tak Grafovém (\texttt{Neo4j\footnote{http://neo4j.com/}}) modu.

Aby aplikace nemusela skladovat v~pamìti pøíli¹ velké mno¾ství dat, data se co nejdøíve po zpracování pøesunou do databáze. Jeliko¾ zpracovaná data ve své podstatì vytváøí orientovaný graf webových dokumentù, byla pro tuto potøebu zvolena grafová databáze. Zpùsob ulo¾ení dat v~databázi tedy co nejvíce pøipomíná zpùsobu ulo¾ení dat na doménì. 

Grafová databáze je sestavena stejnì jako graf ze dvou základních stavebních prvkù. Vrcholy a hrany mezi vrcholy. Jako vrcholy si mù¾eme napøíklad pøedstavit dokumenty, hrany by poté mohly být odkazy mezi tìmito dokumenty. V~sekci Implementace databáze \ref{sec:impl_database} je vìnovaná èást návrhu databáze a její propojení s~aplikací.

\subsection{Souborový systém}
\label{subsec:data_filesystem}
Pokud se s~ka¾dým webovým objektem do databáze ulo¾í i identifikátor, je pak mo¾no tento identifikátor vyu¾ít k~sestavení struktury adresáøù na souborovém systému. Do tìchto adresáøù by se ukládala data, která by jednodu¹e nebylo praktické ukládat do databáze. Jedná se o~vykreslené webové snímky a dal¹í pøíli¹ velká data.

Je nutno také podotknout, ¾e takto ulo¾ená data na více místì ztrácí integritu. Databáze mù¾e být pøítomná na vzdáleném serveru a staèí nám znát pouze adresu a pøístupové údaje ke zpøístupnìní jejích dat. V~pøípadì souborového systému musí být tento systém v¾dy nìjakým zpùsobem pøipojen k~systému, na kterém bì¾í aplikace.

\section{Vykreslení dokumentu}
\label{sec:resource rendering}
Pro vykreslování webových dokumentù byl vyu¾it Headless browser \texttt{PhantomJS 2.0}. PhantomJS obsahuje vykreslovací jádro WebKit, lze s~ním tedy emulovat vykreslování podobné prohlí¾eèùm se stejným jádrem jako je napø Google Chrome, Safari èi Opera \cite{phantomjs}. 

PhantomJS je plnì ovladatelný Javascriptem. Program se spustí s~parametrem cesty k~javascriptovému souboru, který obsahuje ovládací skript prohlí¾eèe. Prohlí¾eè vykoná instrukce v~tomto skriptu a poté se ukonèí. Aplikace spou¹tí prohlí¾eè s~jednoduchým skriptem, který pøistoupí na adresu, obsah vykreslí do souboru a poté se ukonèí.

\section{Projekty}
\label{sec:projects}
Aplikace by mìla být znovupou¾itelná pro vìt¹í poèet analýz domén a jejich procházení. Proto jsem se rozhodla analýzy rozdìlit na tzv. projekty. Jeden projekt je analýza jedné domény. Projekt je mo¾né vytvoøit, spustit analýzu, prohlí¾et výsledky a smazat.

Projekt je primárnì ulo¾en v~databázi s~vìt¹inou dat. Data nevhodná k ulo¾ení do databáze jsou ulo¾ena v~souborovém systému a projekt by je mìl být schopen nalézt.

\section{Návrh u¾ivatelského rozhraní}
\label{sec:draft_gui}
Pøi návrhu jsem se pokusila klást dùraz na jednoduché ovládání, aby program byl schopen ovládat i mirnì pokroèilý u¾ivatel internetu. 

U¾ivatel má být schopen v~aplikaci plnì pracovat s~projekty. Má tedy mo¾nost vytvoøit nový projekt, nebo otevøít ji¾ vytvoøený, spustit analýzu domény èi smazat ji¾ hotovou analýzu a hlavnì procházet výsledky analýzy. Pro zobrazení a procházení výsledkù jsem se rozhodla výsledek analýzy graficky reprezentovat jako graf. Ov¹em graf s~vìt¹ím mno¾stvím objektù se u¾ivateli mù¾e zdát nepøehledný. Z~tohoto dùvodu jsem zvolila zpùsob zobrazení právì procházeného uzlu a jeho nejbli¾¹í okolí v~orientovaném grafu. Po poklikání na kterýkoliv vrchol v~zobrazení se tento vrchol a jeho nejbli¾¹í okolí otevøe.

\newpage
\chapter{Implementace aplikace}
\label{ch:implementation}
Tato kapitola je vìnována implementace návrhu v~pøedchozí kapitole a tomu, jak se závereèná implementace oproti návrhu zmìnila.

Aplikace JavaFX podléhají MVC návrhu, tedy \texttt{Model-View-Controller}. Jádro aplikace, tedy datový model, je oddìlen od zobrazovací vrstvy. S~datovým modelem pøímo komunikuje Controller, tedy øídící prvek. Øídící prvek komunikuje takté¾ s~View, tedy pohledem, pøes mno¾inu komponent, která je v~pohledu definovaná. Øídící prvek sleduje a reaguje na zprávy zaslané pohledem, které zpracovává a pøeposílá dále. Pokud se jedná o~vlastnosti èi parametry modelu, øídící prvek je mù¾e pevnì obou èi jednostrannì svázat s~komponentou. Napø. vlastnost modelu datového typu String mù¾e být svázaná s~komponentou text v~pohledu. Pøi jakékoliv zmìnì této vlastnosti v~modelu je komponenta aktualizována.

V~datovém modelu je obsa¾ena hlavní funkcionalita aplikace. Jádro celé aplikace zastupuje tøída \texttt{Crawler}. Crawler je spu¹tìn ve stejném vláknì jako øídící prvky a pohledy. Funguje jako hlavní øídící jednotka. Pokud u¾ivatel zadá pøíkaz k~modifikaci projektu èi spu¹tìní analýzy, Crawler pøepo¹le pøíkaz slu¾bám v~samostatných vláknech, nebo vytvoøí dedikované vlákno pro splnìní úlohy. Toto se provádí zejména pøi zpracovávání slo¾itých pøíkazù, které by èinily u¾ivatelské rozhraní neresponzivní.

Mezi slu¾by, které spravuje tøída Crawler, patøí sbìraè odkazù (sestavení grafu) a doplnìní dodateèných informací (vykreslování stránek obsahující DOM strom).

\section{Analýza domény}
\label{sec:domain_analysis}

Slu¾by, které zprostøedkovávají analýzu domény s~hlavní tøídou komunikují pouze omezenou mno¾inou zpráv oznamující úspìch èi neúspìch analýzy. Zpracovaná data jsou pøedána prostøednictvím databáze èi souborového systému.

\subsection{Tvorba grafu}
\label{subsec:domain_analysis_graph}

Slu¾ba sestavující graf webových objektù pracuje jako fronta odkazu. Z~fronty slu¾ba odebere odkaz, u~kterého nejdøíve zjistí, zda-li se odkaz nachází v~prohledávaném prostoru. Pokud je objekt mimo prohledaný prostor do databáze se ulo¾í objekt s~minimálním mno¾stvím informací. V~opaèném pøípadì je objekt sta¾en a prozkoumám nástrojem \texttt{jsoup}. Nástrojem jsou prozkoumány tagy a jejich atributy zmínìne v~sekci \ref{sec:extraction}, ve¹keré nalezené odkazy jsou vlo¾eny do zpìt do fronty. Jestli-¾e se jedná o~objekt bez DOM èásti je objekt pova¾ován za soubor a do databáze vlo¾en jeho záznam. Po ulo¾ení objektu je do databáze vlo¾en také odkaz samotný v~podobì hrany. Slu¾ba si také udr¾uje v~pamìti objekty, které ji¾ jednou zpracovala. Nedochází tak k~opakovanému stahování a zpracování ji¾ hotových objektù.

\begin{figure}[H]
  \centering
  \scriptsize
  \includesvg[width=13cm]{miner}
  \caption{Proces zpracování odkazu} \label{fig:miner}
\end{figure}


\subsection{Doplnìní dodateèných informací}
\label{subsec.domain_analysis_postprocessing}

V~èase spu¹tìní druhé èásti analýzy je v~databázi pøítomen ji¾ hotový graf objektu s~jejich základními informacemi. Slu¾ba z~databáze extrahuje objekty, které obsahují DOM strom, a pro ka¾dý z~tìchto objektù nejdøíve vytvoøí své místo ve stromu souborového systému, kam bude slu¾ba pozdìji ukládat informace o~objektu. Cesta k~tomuto adresáøi se skládá z~názvu projektu a specialního identifikátoru pøiøazeného Orient databází. Po dokonèení pøípravy zapoène spou¹tìní externího webového prohlí¾eèe \texttt{PhantomJS} se skriptem, který webovou stránku vykreslí do obrázku a zároveò zaznamená Javascriptový konzolový výstup pøi zpracování stránky do soubory. V~konzolovém výstupu se èasto objevují chyby pøi vykreslování stránek.


\section{Databáze}
\label{sec:impl_database}

Orient Databáze mù¾e pracovat s~objekty ve dvou modifikacích, jako dokument a jako graf. Ka¾dý z~tìchto dvou módù se hodí pro jinou aplikaci. Jak ji¾ bylo zmínìno v~sekci \ref{subsec:data_database}, pro ukládání webových objektù je pøirozenìj¹í pou¾ít mod grafu. Naopak pro práci s~frontou zmínìnou v~sekci \ref{subsec:domain_analysis_graph} je výhodnìj¹í pracovat s~dokumenty. 
Aplikace je propojena s~databází pøes nativní Java konektor. Konektor je schopen pracovat v~tìchto dvou modech. Nabízí pro to øadu konstrukcí a metod. Orient databáze umo¾òuje také pou¾ít SQL jazyk, tento jazyk je narozdíl od napø. Oracle SQL jazyku znaènì omezený, ale obsahuje øadu základních agregaèních metod a klauzulí, které jsou pro aplikaci dostaèující.

Orient Databáze nezná pojem tabulka, místo ní zavádí pojem tøída. Tøída má schopnost dìdiènosti. Pokud chce u¾ivatel vytvoøit tøídu, která bude uzlem nebo hranou v~grafu, vytvoøí tøídu, která bude dìdit vlastnosti abstraktních tøíd V~èi E. Tyto tøídy jsou ji¾ v~databázi pøítomny po jejím vytvoøení. V~pøípadì, ¾e u¾ivatel vytvoøí tøídu, která nebude dìdit vlastnosti z~jedné z~tìchto tøíd, bude tato tøída chápana jako dokument.

Orient Databáze ukládá záznamy tøíd do tzv. clusterù. Ka¾dá tøída má alespoò jeden cluster, do kterého ukládá svá data. Clusterù mù¾e být více, vkládání do nich mù¾e být provádìno pøímo èi na základì algoritmu. Clustery jsou od sebe fyzicky oddìleny, tato vlastnost se vyu¾ívá obzvlá¹» pokud databáze bì¾í v~redistribuèním modu na nìkolika serverových jednotkách \cite{orient}. Mnoho databázi trpí pøi neustále rostoucím objemu dat, slo¾ité dotazy v~takovém pøípadì trvají mnohem déle, ne¾ by trvaly v~malých databázích. Pøitom postupem èasu se v~databázi zaènou objevovat data, ke kterým se bude pøistupovat ménì èi témìø vbùec. Pokud se taková data pøesunou do jiných clusterù a databáze pracuje s~jednim clusterem, které má omezené mno¾ství dat, lze takto rychlost dostazù podstatnì navý¹it.

\begin{figure}[H]
  \centering
  \small
  \includesvg[width=6cm]{clusters}
  \caption{Databázový cluster}
\end{figure}

Data, které aplikace ukládá do databáze jsou v~podstatì rozdìlená do projektù jak ji¾ bylo zmínìno v~sekci \ref{sec:projects}. Pokud ka¾dý projekt bude mít své clustery, které se vytvoøí v¹em tøídám se kterými projekt pracuje lze tak spolehlivì oddìlit data ka¾dé projektu a vyøe¹it tak problém, který by zpùsoboval rostoucí dobu vykonávaní dotazù s~vìt¹ím mno¾stvím ji¾ analyzovaných projektù.

\subsection{Schéma databáze}

V~tabulce \ref{tab:db_classes} a diagramu \ref{fig:db_schema} je znázornìno jak vypadá finální schéma databáze. Projektové clustery se tvoøí v~tøídách \texttt{Resource, Form, BlackWhitelist, LinkTo, Includes, LinkQue, LinkSet}. Název tìchto clusterù se sestává spojením názvu tøídy a unikátnímu identifikátorù, který je ulo¾en jako vlastnost \texttt{cluster} ve tøídì \texttt{Project}.

\begin{table}[H]
  \begin{center}
    \begin{tabular}{| c | c | l |}
      \hline
      \textbf{Název} & \textbf{Typ} & \textbf{Popis} \\
      \hline
      \texttt{Resource} & Vrchol & Webový objekt \\
      \hline
      \texttt{Form} & Vrchol & Formuláø \\
      \hline
      \texttt{Project} & Vrchol & Projekt \\
      \hline
      \texttt{LinkTo} & Hrana & Odkaz mezi dokumenty \\
      \hline
      \texttt{Includes} & Hrana & Pøipojení formuláøe k~dokumentu \\
      \hline
      \texttt{Root} & Hrana & Odkaz na koøenový dokument prohledávané domény \\
      \hline
      \texttt{BlackWhitelist} & Vrchol & Omezení prohledávaného prostoru \\
      \hline
      \texttt{LinkQue} & Dokument & Fronta pro skladování odkazù èekající na zpracování \\
      \hline
      \texttt{LinkSet} & Dokument & Mapa nav¹tívených objektù \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Tøídy databáze} \label{tab:db_classes}
\end{table}

\begin{figure}[H]
  \centering
  \tiny
  \includesvg[width=14cm]{db-schema}
  \caption{Diagram databáze} \label{fig:db_schema}
\end{figure}

\section{Grafické rozhraní}
\label{sec:gui}
JavaFX umo¾òuje mo¾nost navrhnout design ve specialní XML konstrukci, která se jmenuje FXML. Designové komponenty se zapisují stejnì jako XML uzly. Uzly mají pøiøazené indetifikátory, které jsou pøedávány controlleru, tedy ovladaèi, co¾ je mezivrstva mezi modelovací a zobrazovací vrstvou.

V~návrhu jsem grafickému rozhraní nevìnovala pøíli¹ mnoho èasu, finální návrh aplikace vznikal mno¾stvím iterací a experimentù s~neustálou obmìnou designových komponent. Aplikace je rozdìlena do nìkolika zálo¾ek. Kromì zálo¾ek u¾ivatel ovládá aplikaci pøes menu panel v~horní èásti aplikace. Ve spoddní èásti aplikace se nachází nìkolik zálo¾ek s~výpisy konzole programu a slu¾eb. Tyto výpisy slou¾í k~informování u¾ivatele o~èinnosti aplikace, jeliko¾ aplikace provádí velké mno¾ství operací na pozadí a u¾ivateli by se mohla zdát neresponzivní. Pravým tlaèítkem s~ikonou gumy u¾ivatel sma¾e obsah právì zvoleného výpisu.

Úvodní okno obsahuje tabulku s~projekty. Projekt je mo¾no otevøít, smazat èi vytvoøit nový.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{reaper-projects}
  \caption{Úvodní okno} \label{fig:reaper_projects}
\end{figure}

V~této zálo¾ce je u¾ivatel schopen zmìnit nastavení prohledávání a to konkrétnì cílovou doménu, hloubku, a vymezení prohledávaného prostoru. Také je schopen smazat data z~ji¾ existující analýzy, anebo zahájit analýzu novou. Jak ji¾ bylo uvedeno v~sekci \ref{sec:domain_analysis}, analýza probíhá ve dvou fázích. Z~dùvodu èasové nároènosti je nutné spustit obì fáze manuálnì. Jeliko¾ druhá fáze zvy¹uje lineárnì nárok na prostøedky a èas k~jejímu vyhotovení a informace získané v~teto fázi nemusí být pro u¾ivatele dùle¾ité.

Po spu¹tìní analýzy aplikace uzamkne velké mno¾ství ovládacích prvkù, dokud analýza není dokonèena. Bez tohoto zabezpeèovacího mechanismu by u¾ivatel byl schopen vydat napøíklad pøíkaz ke smazání dat, zatímco jsou stahována, a zapøíèinil tak nedefinované chování aplikace.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{reaper-projectoptions}
  \caption{Ovládání analýzy} \label{fig:reaper_analysis}
\end{figure}


Pøi naètení projektu se v~zálo¾ce výsledky naète koøenový objekt analýzy. Procházení výsledkù je rozdìleno do zobrazení grafu vlevo a seznam právì zobrazených objektù, vèetnì detailu procházeného objektu. 
Graf je vsazen do prohlí¾eèe, kde jej vykresluje Javascriptová knihovna \texttt{Vis.js} . Tato knihovna nabízí jednoduchou funkcionalitu pro vykreslování èasových diagramù a grafù. Graf je vykreslen nìkolikabarevnì, ka¾dá z~barev oznaèuje typ webového objektu. U~hran mezi uzly je také zobrazeno èíslo, toto èíslo reprezentuje kolik odkazù dohromady vede mezi dvìma webovými objekty. V~pravém horním rohu jsou 3 checkboxy, pomoci kterých u¾ivatel ovládá, jaké typy webových objektù se v~grafu zobrazí.
V~pravém panelu je ve dvou zálo¾kách umístìn seznam zobrazených objektù v~tabulce a takté¾ detail právì procházeného objektu. Mno¾ství informací zobrané v~detailu závisí na typu webového objektu. Napø. u~objektu, který nebyl skenován je zobrazeno pouze adresa. Oproti tomu objekt s~DOM stromem obsahuje i seznam odkazù, formuláøù, které objekt obsahuje, èi napø obrázek vykreslené stránky.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{reaper-results}
  \caption{Výsledky analýzy} \label{fig:reaper_results}
\end{figure}

V~zálo¾ce statistik jsou zobrazeny dva grafy s~tabulkou jejich hodnot. Levý graf reprezentuje, z~jakých webových objektù v~jakém mno¾ství je slo¾ena prohledaná oblast. V~pravém grafu je vidìt, jaké odpovìdi serveru byly vráceny. Nutno podotknout, ¾e napø. chybu 404 mnohé webové stránky nevrací správnì; u¾ivateli je zobrazeno hlá¹ení, ¾e hledaný obsah nebyl nalezen, server ale ve skuteènosti odpoví kódem 200.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{reaper-stats}
  \caption{Statistiky} \label{fig:reaper_stats}
\end{figure}


\section{Webové rozhraní}
\label{sec:web_interface}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.65]{web}
  \caption{Webové rozhraní} \label{fig:web}
\end{figure}

Díky pou¾ití technologie JavaFX je mo¾né aplikaci pou¾ít jako desktopový program, nebo jí vsadit do webové stránky jako Java applet. Java applet narozdíl od webové aplikace spotøebuje ke svému bìhu vìt¹í mno¾ství zdrojù a mù¾e se projevit jako pomalej¹í ne¾ desktopová verze.

V~pøípadì vyu¾ítí appletu na webových stránkách je nutné poèítat se zpøísnìným bezpeènostním opatøením Javy 1.8. Ve¹keré applety musí být podepsány platným certifikátem od uznávané autority, jinak jim není umo¾nìno spou¹tìní v~prohlí¾eèi. Takovýto certifikát se dá zakoupit a vygenerovat u~certifikaèních autorit. Pro úèely této práce jsem applet pouze testovala v~lokálním webovém prostøedí, kde jsem tyto bezpeènostní direktivy vypnula.

Dal¹í z~problému, který se v~této oblasti objevil je rozhodnutí spoleènosti Google, stojící za prohlí¾eèem Google Chrome, o~ukonèení podpory architektury \texttt{NPAPI}. Po nabytí úèinnosti tohoto rozhodnutí na konci roku 2015 nebude mo¾né spustit Java kod v~prohlí¾eèi Google Chrome\cite{npapi}, aplikace by tak byla podporována pouze v~prohlí¾eèích Firefox, Internet Explorer a Safari.
Mo¾ným øe¹ením tohoto problému by byl návrh èistì webové aplikace bez pou¾ití NPAPI architektury, která by mìla pøístup k~vytvoøené databázi a zároveò k~souborovému systému s~ulo¾enými vykreslenými snímky analýzy. 
\newpage
\chapter{Výsledky}
\label{ch:experiments}
Experimenty jsem provádìla na následující konfiguraci.
\begin{table}[H]
  \begin{center}
    \begin{tabular}{| c | l |}
      \hline
      CPU & FX-6300 3,5GHz \\
      \hline
      RAM & 12GB DDR3 \\      
      \hline
      OS & Fedora 20 \\
      \hline
      Java & JDK 1.8.0\_40 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{HW/SW konfigurace} \label{tab:db_classes}
\end{table}

Analýzy jsem provádìla na doménách s~rùzným poètem webovým objektù. Jako men¹í oznaèuji v¹echny domény, jejich¾ analýza objevila ménì jak 1000 objektù. Vìt¹í domény jsou pak ty, které toto èíslo pøesáhly. Bìhem analýzy byla ka¾dá stránka sta¾ena a zpracována.

Spotøeba RAM pamìti aplikace po nìkolika hodinách spu¹tìné analýzy nepøekroèila 1 GiB. Toto pova¾uji za veliký úspìch, proto¾e se tím podaøilo vyøe¹it problémy prototypu zmínìného v~kapitole návrhu aplikace \ref{ch:plan}. Na úkor spotøeby zdrojù aplikace se projevil potøebný èas k~dokonèení analýzy. U~domén skládajících se z~desítky tisíc odkazù je analýza velice pomalá, napø. analýza portálu seznam.cz se dostala do tøetí úrovnì odkazu a¾ po nìkolika hodinách. 

\begin{table}[H]
  \begin{center}
  \small
    \begin{tabular}{| l | c | c | c | c | c | r |}
      \hline
      \multicolumn{1}{|c|}{\textbf{URL}} & \multicolumn{3}{| c |}{\textbf{Webové objekty}}  & \textbf{Odkazy} & \textbf{Fronta\tablefootnote{Poèet odkazù èekající na zpracování}} & \multicolumn{1}{|c|}{\textbf{T}\tablefootnote{Délka první èásti analýzy}}\\
      \hline
      & Stránky & Soubory & Neskenované\tablefootnote {Mezi neproskenované objekty se poèítají objekty, které se nacházely mimo prohledávaný prostor, èi objekty za hranicemi hloubky analýzy.} & & &\\
      \hline
      http://jsoup.org & 503 & 11 & 110 & 6440 & 0 & 16:32\\
      \hline
      http://visjs.org & 144 & 42 & 113 & 1440 & 0 & 1:05 \\
      \hline
      http://seznam.cz & 313 & 155 & 267 & 1416 & 21998 & 3:31:15 \\
      \hline
      http://phantomjs.org & 193 & 2 & 505 & 12458 & 0 & 1:05:15 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Tabulka výsledkù analýz} \label{tab:results}
\end{table}

®ádná analýza domén s~vìt¹ím poètem objektù nebyla dokonèena bìhem jednoho spu¹tìní. Stávalo se, ¾e bìhem analýzy vypadlo internetové pøipojení, èi doèasnì neodpovídala databáze. Z~tìchto dùvodu jsem provedla úpravy v~programu, aby se ve¹keré data bìhem analýzy ukládala do databáze. Výsledkem tohoto sna¾ení jsou tøídy \texttt{LinkQue} a \texttt{LinkSet}. V~pøípadì opìtovného spu¹tìní analýzy aplikace pokraèuje v~analýze tam, kde pøi pøedchozím spu¹tìní pøestala.

I~pøesto se mi nepodaøilo prozkoumat tyto velké domény do vìt¹ích hloubek, se vzrùstajícím poètem záznamù v~databázi se rychlost zpracování dotazù èím dál víc zpomalovala a po nìkolika hodinách zpracovaný poèet odkazù se pohyboval kolem nìkolika tisíc a poèet odkazù ve frontì se neustále zvy¹oval k~nìkolika desítkám tisíc.

\newpage
\chapter{Dal¹í mo¾ná roz¹íøení}
\label{ch:enhacements}
Nìkteré èásti této aplikace jsou zpracovány velice jednodu¹e a existuje mnoho mo¾ností jak by dál mohly roz¹íøit. Zde je uveden seznam vìcí, které jsou nad rámec rozsahu bakaláøské práce.

Jak první, tak druhá èást analýzy probíhá synchronnì v~jednom vláknì. Tato vlastnost nevyu¾ívá dostateènì zdroje poèítaèe a analýza je z~tohoto dùvodu velmi pomalá. Prvním krokem k~napravení by bylo roz¹íøit první èást analýzy k~vyu¾ití nìkolika vláken. Druhá èást analýzy pøi ka¾dém spu¹tìní externího programu èeká na jeho ukonèení, spou¹tìním nìkolika procesù zároveò by se dosáhlo lep¹ích výsledkù.
Dal¹í podstatnì nároènìj¹í mo¾ností by bylo rozdìlení slu¾eb provádìjící analýzu a sí» klientských programù na více zaøízení. Tyto programy by pracovaly na jedné doménì souèasnì a jako svùj hlavní komunikaèní prostøedek by vyu¾ily databázi.

Zálo¾ka statistik zmínìná v~sekci \ref{sec:gui}, je chudá na dùle¾ité informace. U¾ivatel se mù¾e prostøednictvím grafu dozvìdìt, ¾e se na doménì nachází objekty, jejich¾ pokus o~zpøístupnìní zpùsobil chybu 500, ale nedozví se, které objekty to byly.
V~zálo¾ce statistik chybí také jakákoliv analýza rychlosti pøístupu na objekty a velikosti objektù. Analýza tyto hodnoty zaznamenává, ale nejsou ve statistice prezentovány. U¾ivatele aplikace by mohlo zajímat, které èásti webových stránek se ukázaly jako nejpomalej¹í, a podrobit tyto èásti podrobnìj¹ím zkoumáním.

Pøi vyhledávání a zkoumání formuláøù se do databáze ukládá jen velmi malé mno¾ství dat, informace o~polích formuláøe zcela chybí.

Ka¾dý webový server je nìèím unikátní; tvoøit nástroje, které se sna¾í vyhovìt v¹em mù¾e být nároènì a¾ nemo¾né. Pokud by aplikace podporovala mo¾nost vlo¾ení u¾ivatelských skriptù pøi práci prohlí¾eèe ve druhé èásti analýzy, byl by u¾ivatel schopen dodefinovat chování pavouka ve specifických pøípadech.

\newpage
\chapter{Závìr}
\label{ch:closure}

Podaøilo se mi vytvoøit aplikaci, která je schopna analyzovat doménu a vytvoøit její graf v~databázi spolu s~údaji o~zmapovaných objektech. Aplikace je postavena na frameworku JavaFX a jako úlo¾i¹tì vyu¾ívá databázi s~grafovým modelem OrientDB. Aplikace je také schopná prezentovat výsledky analýzy u¾ivateli. Data jsou ulo¾ena na u¾ivateli pøístupné místo k~dal¹ímu zpracování/vyu¾ití.

Aplikace si neklade pøíli¹ velké nároky na dostupné prostøedky. Namísto toho prodlu¾uje celkový èas analýzy. Z~experimentù je mo¾né vyvodit, ¾e aplikace není vhodná pro analýzu dynamických a obsahovì rozsáhlých domén. Mù¾e ov¹em být u¾iteèná pro domény s~men¹ím a hlavnì statickým obsahem. Pøi opakovaném spu¹tìní mù¾eme pozorovat zmìny ve~struktuøe webových objektù i jejich mno¾ství.

Pøi implementaci aplikace mì napadlo mnoho dal¹ích roz¹íøení a smìrù, kam by vývoj aplikace mohl dále pokraèovat, tato roz¹íøení jsou popsána v~kapitole \ref{ch:enhacements}.

%=========================================================================
